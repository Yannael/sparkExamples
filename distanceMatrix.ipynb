{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance matrix computation in Spark (High feature/sample ratio)##\n",
    "\n",
    "###Notations###\n",
    "* Let $X$ be a matrix with $n$ features (rows) and $N$ observations (columns), $n\\gg N$. \n",
    "* Let $x_i$, $1 \\le i \\le n$ be the $i$-th row of X (of size $N$). \n",
    "* Let D be the $n \\times n$ matrix of distances between all pairs of features of $X$. \n",
    "* Let $d_{ij}$ be the distance between features $i$ and $j$, $d_{ij}=d(x_i,x_j)$. \n",
    "\n",
    "###Approach: Block partitioned matrix###\n",
    "\n",
    "Let $X$ be partitioned into $p$ row blocks of size $n_p \\times N$\n",
    "$$X = \\left[\\begin{array}\n",
    "{r}\n",
    "X_1  \\\\\n",
    "X_2  \\\\\n",
    "...\\\\\n",
    "X_p\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "and the distance matrix be partitioned in $p^2$ row and column blocks\n",
    "\n",
    "$$D = \\left[\\begin{array}\n",
    "{rrrr}\n",
    "D_{11} & D_{11} & ... & D_{1p} \\\\\n",
    "D_{21} & D_{22} & ... & D_{2p} \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "D_{p1} & D_{p2} & ... & D_{pp} \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "**The distributed implementation will consist in computing $D_{ij}$ in parallel**.\n",
    "* **Stage 1**: Mapping. Partition $X$ in $p$ blocks. Key is the partition id, value is $X_k$, $1 \\le k \\le p$.\n",
    "* **Stage 2**: Mapping. For each block $X_k$, replicate the block $p$ times. Key is the pair $(k,l)$, $1 \\le l \\le p$, value is $X_k$.\n",
    "* **Stage 3**: Group by. Groups $X_k$ and $X_l$ for each pair $(k,l)$. Key is the pair $(k,l)$, value is the pair $(X_k,X_l)$ if $k \\ne l$, or the singleton ($X_k$) if $k=l$.\n",
    "* **Stage 4**: Reduce. For each pair $(k,l)$, compute block distance matrix $D_{kj}$.\n",
    "\n",
    "###Spark implementation (Python)###\n",
    "\n",
    "In the following the distance function is the Pearson correlation.\n",
    "\n",
    "####Context initialization####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[2]\", \"correlationExample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For random number generation and matrix operation\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29712212,  0.95591243,  0.37373404],\n",
       "       [ 0.23117962,  0.96107945,  0.8316498 ],\n",
       "       [ 0.06633115,  0.15409498,  0.52527106],\n",
       "       [ 0.38767595,  0.69526431,  0.09503964],\n",
       "       [ 0.58534828,  0.13666517,  0.04192201],\n",
       "       [ 0.22321103,  0.29025997,  0.56436033]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a random matrix\n",
    "N=3 #Number of columns\n",
    "n=6 #Number of rows\n",
    "matrix=np.random.random((n,N))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Stage 1####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let us define 3 partitions\n",
    "p=3\n",
    "stage0=sc.parallelize(matrix,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(splitIndex ,v): \n",
    "    return [(splitIndex,list(v))]\n",
    "\n",
    "stage1=stage0.mapPartitionsWithIndex(lambda splitIndex,v: f(splitIndex,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [array([ 0.29712212,  0.95591243,  0.37373404]),\n",
       "   array([ 0.23117962,  0.96107945,  0.8316498 ])]),\n",
       " (1,\n",
       "  [array([ 0.06633115,  0.15409498,  0.52527106]),\n",
       "   array([ 0.38767595,  0.69526431,  0.09503964])]),\n",
       " (2,\n",
       "  [array([ 0.58534828,  0.13666517,  0.04192201]),\n",
       "   array([ 0.22321103,  0.29025997,  0.56436033])])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Stage 2####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePairParts(k,v,p):\n",
    "    return [(str(sorted([k,l])),(k,v)) for l in range(0,p)]\n",
    "\n",
    "stage2=stage1.flatMap(lambda (k,v):makePairParts(k,v,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[0, 0]',\n",
       "  (0,\n",
       "   [array([ 0.29712212,  0.95591243,  0.37373404]),\n",
       "    array([ 0.23117962,  0.96107945,  0.8316498 ])])),\n",
       " ('[0, 1]',\n",
       "  (0,\n",
       "   [array([ 0.29712212,  0.95591243,  0.37373404]),\n",
       "    array([ 0.23117962,  0.96107945,  0.8316498 ])])),\n",
       " ('[0, 2]',\n",
       "  (0,\n",
       "   [array([ 0.29712212,  0.95591243,  0.37373404]),\n",
       "    array([ 0.23117962,  0.96107945,  0.8316498 ])])),\n",
       " ('[0, 1]',\n",
       "  (1,\n",
       "   [array([ 0.06633115,  0.15409498,  0.52527106]),\n",
       "    array([ 0.38767595,  0.69526431,  0.09503964])])),\n",
       " ('[1, 1]',\n",
       "  (1,\n",
       "   [array([ 0.06633115,  0.15409498,  0.52527106]),\n",
       "    array([ 0.38767595,  0.69526431,  0.09503964])])),\n",
       " ('[1, 2]',\n",
       "  (1,\n",
       "   [array([ 0.06633115,  0.15409498,  0.52527106]),\n",
       "    array([ 0.38767595,  0.69526431,  0.09503964])])),\n",
       " ('[0, 2]',\n",
       "  (2,\n",
       "   [array([ 0.58534828,  0.13666517,  0.04192201]),\n",
       "    array([ 0.22321103,  0.29025997,  0.56436033])])),\n",
       " ('[1, 2]',\n",
       "  (2,\n",
       "   [array([ 0.58534828,  0.13666517,  0.04192201]),\n",
       "    array([ 0.22321103,  0.29025997,  0.56436033])])),\n",
       " ('[2, 2]',\n",
       "  (2,\n",
       "   [array([ 0.58534828,  0.13666517,  0.04192201]),\n",
       "    array([ 0.22321103,  0.29025997,  0.56436033])]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Stage 3####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage3=stage2.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [array([ 0.29712212,  0.95591243,  0.37373404]),\n",
       "   array([ 0.23117962,  0.96107945,  0.8316498 ])]),\n",
       " (2,\n",
       "  [array([ 0.58534828,  0.13666517,  0.04192201]),\n",
       "   array([ 0.22321103,  0.29025997,  0.56436033])])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stage3.collect()[2][1]) #Example of the content for pair (0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Stage 4####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Faster implementation of matrix correlation in Python\n",
    "#http://stackoverflow.com/questions/30143417/computing-the-correlation-coefficient-between-two-multi-dimensional-arrays\n",
    "def corr2_coeff(A,B):\n",
    "    A_mA = A - A.mean(1)[:,None]\n",
    "    B_mB = B - B.mean(1)[:,None]\n",
    "    ssA = (A_mA**2).sum(1);\n",
    "    ssB = (B_mB**2).sum(1);\n",
    "    return np.dot(A_mA,B_mB.T)/np.sqrt(np.dot(ssA[:,None],ssB[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCorrelation(k,v):\n",
    "    pairBlock=list(v)\n",
    "    pairBlock1=pairBlock[0][0]\n",
    "    \n",
    "    blockMatrix1=pairBlock[0][1]\n",
    "    if (len(pairBlock)==1):\n",
    "        blockMatrix2=pairBlock[0][1]\n",
    "        k=(pairBlock[0][0],pairBlock[0][0])\n",
    "    else:\n",
    "        blockMatrix2=pairBlock[1][1]\n",
    "        k=(pairBlock[0][0],pairBlock[1][0])\n",
    "    \n",
    "    corrB1B2=corr2_coeff(np.array(blockMatrix1),np.array(blockMatrix2))\n",
    "    \n",
    "    return (k,corrB1B2)\n",
    "\n",
    "stage4=stage3.map(lambda (k,v):getCorrelation(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 1), array([[-0.23377681,  0.81634516],\n",
       "         [ 0.51222424,  0.18032957]])),\n",
       " ((1, 1), array([[ 1.        , -0.75240277],\n",
       "         [-0.75240277,  1.        ]])),\n",
       " ((0, 2), array([[-0.44949702, -0.22847719],\n",
       "         [-0.94576292,  0.51689488]])),\n",
       " ((1, 2), array([[-0.76344727,  0.99998516],\n",
       "         [ 0.14898302, -0.7488036 ]])),\n",
       " ((2, 2), array([[ 1.        , -0.76695405],\n",
       "         [-0.76695405,  1.        ]])),\n",
       " ((0, 0), array([[ 1.        ,  0.71530707],\n",
       "         [ 0.71530707,  1.        ]]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###All in one line###\n",
    "Note that using Spark pipelining, you may express the execution of all stages in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=sc.parallelize(matrix,p).mapPartitionsWithIndex(f).flatMap(lambda (k,v):makePairParts(k,v,p)).groupByKey().map(lambda (k,v):getCorrelation(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 1), array([[-0.23377681,  0.81634516],\n",
       "         [ 0.51222424,  0.18032957]])),\n",
       " ((1, 1), array([[ 1.        , -0.75240277],\n",
       "         [-0.75240277,  1.        ]])),\n",
       " ((0, 2), array([[-0.44949702, -0.22847719],\n",
       "         [-0.94576292,  0.51689488]])),\n",
       " ((1, 2), array([[-0.76344727,  0.99998516],\n",
       "         [ 0.14898302, -0.7488036 ]])),\n",
       " ((2, 2), array([[ 1.        , -0.76695405],\n",
       "         [-0.76695405,  1.        ]])),\n",
       " ((0, 0), array([[ 1.        ,  0.71530707],\n",
       "         [ 0.71530707,  1.        ]]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Resources##\n",
    "* [Wang S, Pandis I, Johnson D, et al. Optimising parallel R correlation matrix calculations on gene expression data using MapReduce. BMC Bioinformatics. 2014;15(1):351. doi:10.1186/s12859-014-0351-9.](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4246436/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
